---
title: "Naturalization Analysis Notebook"
output:
  html_document:
    df_print: paged
    code_folding: hide
    toc: true
    toc_float: true
    toc_collapsed: false
---


```{r, message = FALSE, warning=FALSE}
require(car)
require(DHARMa)
require(emmeans)
require(MASS)
require(effects)
require(glmmTMB)
require(lme4)
require(kableExtra)
require(gt)
require(gtsummary)
require(tidyverse)
require(magrittr)
require(countreg)
require(lmerTest)
require(lubridate)
require(khroma)
```


# Summary

This notebook contains a log of all analyses associated with the manuscript titled: A single generation in the wild increases fitness for descendants of hatchery Chinook salmon (_Oncorhynchus tshawytscha_)

This is an R notebook. The .html version of this file is a fully rendered and interactive log. To view it, save the html and open in a browse. The .rmd version can be opened within R studio. To reproduce results or edit the analysis: clone the full repository onto your local machine and open the r project in rstudio. This will provide all needed data and objects.

# Pedigrees, Cohorts, Variables and Rationale of Comparisons

This notebook relies on a pedigree of all Chinook Salmon released above Cougar Dam on the South Fork McKenzie River from 2007 - 2017 using potential offspring sampled from 2010 to 2020. 

## Summary of Cohort Years

Nearly all (98%) Chinook salmon on the South Fork McKenzie express an age at maturity of 4 - 5 years, with approximately 2% returning at age 3 or age 6. Therefore, our data data allow us to identify all offspring of salmon released above Cougar Dam in 2010 - 2014, and nearly all offspring of salmon released above Cougar Dam in 2015. From the offspring's perspective, we sample all possible parents of potential offspring that return from 2013 - 2020, and nearly all (98%) parents of potential offspring that returned in 2012. 

Therefore for adults that return and are released above the dam from 2012 - 2015, we know both their parentage (i.e. who are their parents) and how many returing adult offspring they produce. 

## Definition of Variables

### TLF  

For each candidate parent (any salmon released above the dam), we define total lifetime fitness (TLF) as the number of adult offspring produced by a individual candidate parent. Adult offspring are identified through parentage analysis, with any salmon collected at the Cougar Trap or during spawning ground surveys above or below the dam evaluated as potential offspring.


### Generation  
This analysis is based on comparisons of TLF between three groups of candidate parent salmon released above Cougar Dam from 2012 - 2015:  

__(1) Hatchery/HOR:__ These are hatchery-origin fish from the McKenzie spring Chinook salmon hatchery program, that are released above the dam.  
__(2) F1:__ We define F1s as the first generation wild born offspring of hatchery salmon released above the dam. Both of their parents are HOR.   
__(3) NORimmigrant:__ We define NOR immigrant salmon as any salmon without an adipose clip that does not assign to a parent previously released above the dam. These salmon are presumed to be produced below the dam or elsewhere (no parentage assignment), and to also be wild born (no adipose clip, McKenzie clip rate > 99%). In the manuscript we will refer to these simply as NOR, but for the notebook we will label as NORimmigrant to avoid confusion with other unclipped fish.   

We refer to this variable as __generation__ in this notebook

__Other fish__   
There are many other individuals in the pedigree that do not fall into one of these three groups:
* Individuals that assign to a single parent  
* Individuals from mixed mate pairs (e.g. HORxF1 parents)  
* Individuals that are never released above the dam and therefore are not candidate parents and have no TLF estimate (e.g. F1 salmon that are recycled downstream of the dam and never return to be released above the dam)  

To keep our conclusions as clear as possible we will ignore these other individuals and focus solely on HORs, F1s and NOR immigrants.

# Data 

Here we import the finalized datasets from the McKenzie River Chinook salmon evaluation, create new datasets for this analysis, and summarize the data.

## Data Import

Here we import and assemble datasets from previous analyses 
```{r}
# load pedigree and full dataset
load("../input_data/full_filtered_dataset.R")
load("../input_data/pedigree.R")

# deduplicate (many individuals are sampled first live and later as carcasses, this defines individuals by their first encounter)
dedup <- full_data_1.0 %>%
  group_by(sample_id) %>%
  slice_max(date, with_ties = FALSE) %>%
  ungroup()
```

```{r}
# let's get the metadata on the pedigree
pedigree_meta <- dedup %>%
  select(sample_id, year, type, date) %>%
  rename_with(.fn = ~ paste0("offspring_", .x)) %>%
  right_join(pedigree, by = c("offspring_sample_id" = "offspring_sample_id"))

#father
pedigree_meta <- dedup %>%
  select(sample_id, year, type, date) %>%
  rename_with(.fn = ~ paste0("father_", .x)) %>%
  right_join(pedigree_meta, by = c("father_sample_id" = "father")) %>%
  rename(father = father_sample_id)

#mother
pedigree_meta <- dedup %>%
  select(sample_id, year, type, date) %>%
  rename_with(.fn = ~ paste0("mother_", .x)) %>%
  right_join(pedigree_meta, by = c("mother_sample_id" = "mother")) %>%
  rename(mother = mother_sample_id)

pedigree_meta %<>%
  mutate(parent_year = (coalesce(father_year, mother_year)))

#let's add a column for the type of assignment, and one for combined types
pedigree_meta %<>%
  mutate(assn_type = case_when((mother == "none" & father == "none") ~ "none",
                               (mother == "none" & father != "none") ~ "male_only",
                               (mother != "none" & father == "none") ~ "female_only",
                               (mother != "none" & father != "none") ~ "pair",)) %>%
  mutate(parent_type = case_when((father_type == mother_type) ~ father_type,
                                 (is.na(father_type) & !(is.na(mother_type))) ~ mother_type,
                                  (is.na(mother_type) & !(is.na(father_type))) ~ father_type,
                                   (father_type != mother_type) ~ paste(mother_type, father_type, sep = "/")))

```

```{r}
# let's not forget the "parents" dataset
parents <- dedup %>%
  filter(cand_parent == TRUE)

father_counts <- pedigree %>%
  group_by(father) %>%
  count() %>%
  rename(parent = father)

mother_counts <- pedigree %>%
  group_by(mother) %>%
  count() %>%
  rename(parent = mother)

parent_counts <- bind_rows(mother_counts, father_counts) 
rm(mother_counts)
rm(father_counts)

parents %<>%
  left_join(parent_counts, by = c("sample_id" = "parent")) %>%
  rename(tlf = n) %>%
  mutate(tlf = replace_na(tlf, 0))

rm(parent_counts)
```


```{r}
# we will also rely heavily on the age at maturity dataset from the main project, let's make that R object here too
aam_data <- pedigree_meta %>%
  mutate(parent_year = (coalesce(father_year, mother_year))) %>%
  filter(!(is.na(parent_year))) %>%
  mutate(age = as.numeric(offspring_year) - as.numeric(parent_year)) %>%
  mutate(age = as.factor(age), offspring_year = as.factor(offspring_year)) 

```

```{r}
# we also use the "mate pair" dataset, we will create this R object here as well

mate_pair <- pedigree_meta %>%
  filter(assn_type == "pair", parent_year < 2016, parent_year > 2009) %>%
  left_join(select(parents, sample_id, origin, tlf), by = c("father" = "sample_id")) %>%
  rename(father_origin = origin, father_tlf = tlf) %>%
  left_join(select(parents, sample_id, origin, tlf), by = c("mother" = "sample_id")) %>%
  rename(mother_origin = origin, mother_tlf = tlf) %>%
  mutate(cross = case_when(mother_origin == "NOR" & father_origin == "HOR" ~ "NxH",
                           mother_origin == "HOR" & father_origin == "NOR" ~ "HxN",
                           mother_origin == "NOR" & father_origin == "NOR" ~ "NxN",
                           mother_origin == "HOR" & father_origin == "HOR" ~ "HxH"))
mate_pair %<>%
  mutate(year_f = as.factor(parent_year),
         cross_f = as.factor(cross)) %>%
  mutate(cross_f = fct_relevel(cross_f, "NxN",   "HxN", "NxH","HxH"))

```

## Primary Dataset

Now let's assemble and summarize the focal dataset for this project. 

We must collect metadata and TLF, filter down to just our target individuals and assign the "generation" variable. We also know a priori that length, sex, and release date are all associated with TLF, so we will need to exclude any individuals where we do not know this information (n = 15, 12 of which are 2014 NOR immigrants). 

```{r, message=FALSE, warning=FALSE}
pedigree_origin <- pedigree %>%
  left_join(select(dedup, sample_id, origin), by = c("mother" = "sample_id")) %>%
  rename(mother_origin = origin) %>%
  left_join(select(dedup, sample_id, origin), by = c("father" = "sample_id")) %>%
  rename(father_origin = origin)

F12_mmdata <- dedup %>%
  filter(year> 2011 , year < 2016, cand_parent == TRUE) %>%
  left_join(pedigree_origin, by = c("sample_id" = "offspring_sample_id")) %>%  # attach parents and their origin 
  mutate(generation = case_when(origin == "HOR" ~ "HOR",
                                mother_origin == "HOR" & father_origin == "HOR" ~"F1",
                                mother_origin == "NOR" & father_origin == "NOR" ~"F2", #see note 1 above for why this makes sense
                                mother == "none" & father == "none" ~ "NORimmigrant",
                                mother == "none" | father == "none" ~ "single_parentage",
                                mother_origin == "HOR" & father_origin == "NOR" ~"HORxNOR",
                                mother_origin == "NOR" & father_origin == "HOR" ~"NORxHOR")) %>%
  left_join(select(parents, sample_id, tlf) ) %>%
  mutate(jday = as.numeric(format(date, "%j"))) %>% #julian day in this case: days since the first day of the year
  mutate(jday_c = scale(jday, scale = F), #center the julian day to help with convergence
         sex = as.factor(sex),
         release= as.factor(release),
         year = as.factor(year),
         group = as.factor(paste(date, release, type))) %>%
  filter(length != 0, !(is.na(length))) %>%
  filter(generation %in% c("HOR", "F1", "NORimmigrant")) %>%
  mutate(generation  = fct_relevel(generation, c("HOR", "F1", "NORimmigrant")))
```

Great, now let's summarise sample size.
```{r}
kable(F12_mmdata %>%
  count(year, generation) %>%
  pivot_wider(id_cols = year, names_from = generation, values_from = n), caption = "Sample Size for the main dataset") %>% 
  kable_classic(full_width = F, html_font = "Arial")
```

Note that we do not have great balance between the years. Most F1s and NOR immigrants come from 2012. We know from the evaluation of the reintroduction that TLF varies between years, so we will need to be careful to investigate collinearity and other interactions between the year, generation and TLF variables. 

# TLF Variation Model

Our principal question is whether there are fitness differences between HORs, F1s and NORimmigrants. To address this question we will fit a generalized linear model mixed on TLF. In addition to the effect of generation we will also explore covariates that we found were associated with TLF in the McKenzie River reintroduction. These include release length, sex, and julian day of release (fit as a linear continuous variable). We have some priors that suggest we should also explore some interactions: a sex * generation interaction and a sex * length interaction. We also fit year as fixed effect (too few to fit as random like we do in the evaluation: n_year = 4). Finally we will include release group as a random effect. A release group is defined as set of individuals released together at the same location on the same day. Previous analyses have suggested that there is substantial variation in TLF among release groups, and the model fit benefits from the shrinkage associated with including release group.

## EDA 

Even though we have already done this work for the full dataset, we will conduct a separate exploratory data analysis prior to fitting a model. This will include a careful examination of collinearity, identifying the correct distribution and link function for modeling, and model validation.

### Predictors

Let's explore our predictor variables.

```{r}
##################################################################
##################################################################
# this is a function to quickly produce biplots between our variables

panel.cor <- function(x, y, digits=1, prefix="", cex.cor = 6)
{
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  r1=cor(x,y,use="pairwise.complete.obs")
  r <- abs(cor(x, y,use="pairwise.complete.obs"))
  txt <- format(c(r1, 0.123456789), digits=digits)[1]
  txt <- paste(prefix, txt, sep="")
  if(missing(cex.cor)) { cex <- 0.9/strwidth(txt) } else {
     cex = cex.cor}
  text(0.5, 0.5, txt, cex = cex * r)
}

##################################################################
panel.smooth2=function (x, y, col = par("col"), bg = NA, pch = par("pch"),
                        cex = 1, col.smooth = "black", span = 2/3, iter = 3, ...)
{
  points(x, y, pch = pch, col = col, bg = bg, cex = cex)
  ok <- is.finite(x) & is.finite(y)
  if (any(ok))
    lines(stats::lowess(x[ok], y[ok], f = span, iter = iter),
          col = 1, ...)
}

##################################################################
panel.lines2=function (x, y, col = par("col"), bg = NA, pch = par("pch"),
                       cex = 1, ...)
{
  points(x, y, pch = pch, col = col, bg = bg, cex = cex)
  ok <- is.finite(x) & is.finite(y)
  if (any(ok)){
    tmp=lm(y[ok]~x[ok])
    abline(tmp)}
}

##################################################################
panel.hist <- function(x, ...)
{
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(usr[1:2], 0, 1.5) )
  h <- hist(x, plot = FALSE)
  breaks <- h$breaks; nB <- length(breaks)
  y <- h$counts; y <- y/max(y)
  rect(breaks[-nB], 0, breaks[-1], y, col="white", ...)
}


F12_mmdata %>%
  select(tlf, sex, jday,  generation, year, length) %>%
  #mutate(tlf = log(tlf)) %>%
  pairs(., lower.panel = panel.cor, diag.panel = panel.hist, upper.panel = panel.smooth2)
```

In the figure above a histogram of each variable is along the diagonal. For the unlabeled factor vairables the levels are (in order) Sex(F, M), Generation (HOR, F1, NORimmigrant).

There are a handful of relationships that jump our even with a simple correlation. The most potentially problematic, as we already noted, is the relationship between generation and year. Generation is also weakly related to release day, sex and length. We will need to explore these in more detail than with this simple figure. 

__Generation x Release Day__  
Let's explore the relationship between release day and generation.

```{r}

ggplot(data = F12_mmdata)+geom_density(aes(x = jday, fill = generation, color = generation), alpha = 0.4)+theme_bw()+scale_fill_manual(values = c("#228833", "#CCBB44", "#AA3377"))+scale_color_manual(values = c("#228833", "#CCBB44", "#AA3377"))+xlab("Julian Day of Release")

```

Yes, there is a relationship between generation and release day. Fortunately there is a lot of overlap so our model may be able to parse the effects and collinearity will not prevent us from making clear inferences.

__Generation x Sex__
```{r}

ggplot(data = F12_mmdata)+geom_bar(aes(x = generation, fill = sex), position = "fill")+scale_fill_bright()+theme_bw()+ylab("Proportion")

```

HORs tend to be female biased relative to F1s and NORimmigrants. We will also need to be thoughtful about the relationship between these variables and TLF

__Generation x Length __
```{r}

ggplot(data = F12_mmdata)+geom_density(aes(x = length, fill = generation, color = generation), alpha = 0.4)+theme_bw()+scale_fill_manual(values = c("#228833", "#CCBB44", "#AA3377"))+scale_color_manual(values = c("#228833", "#CCBB44", "#AA3377"))+xlab("Length (cm)")

anova(lm(length ~ generation + year, data = F12_mmdata))
plot(emmeans(lm(length ~ generation + year, data = F12_mmdata), "generation", type = "response"))
contrast(emmeans(lm(length ~ generation + year, data = F12_mmdata), "generation", type = "response"), "pairwise")

```

HORs are significantly smaller than both F1s and NORimmigrants. F1s and NOR immigrants are the same length. 

### Distribution

In all recent pedigree work on UWR reintroductions, a negative binomial distribution was a better fit to the data and/or more parsimonious fit than Poisson, QuasiPoisson, and various zero-inflation/hurdle models. However the zero-inflated negative binomial and negative binomial models were pretty close in performance. Let's re-evaluate given that the zero-inflated model may perform better on this data subset. 

For each of the two approaches (negbin and zero-inlfated negbin (zinb)) we'll conduct model selection then we'll compare the optimal models. Most of the model selection procedures I already have running won't work well on the zero-inflated model so we'll just follow the reccomendations of Zuur et al and rely on backwards stepwise Wald Tests, treating each component (zeros and conditional) separately. We will also ignore the random effects for now.  

```{r}
negbin <- glmmTMB(tlf ~ generation + length + sex+ jday_c+ year, data = F12_mmdata, family = nbinom2)
summary(negbin)

# drop sex (p = 0.56, wald test)
negbin <- glmmTMB(tlf ~ generation + length + jday_c+ year , data = F12_mmdata, family = nbinom2)
summary(negbin)

# release day is marginal, let's keep it for now
```

```{r}
zinb <- glmmTMB(tlf ~ jday_c + sex + generation +length +year , zi = ~ jday_c + sex + generation +length +year , data = F12_mmdata, family = nbinom2)
summary(zinb)

#sex and length have p-values ~ 1 in the zero part of the model, remove
zinb <- glmmTMB(tlf ~ jday_c + sex + generation +length +year , zi = ~ jday_c + generation  +year , data = F12_mmdata, family = nbinom2)
summary(zinb)

# next out is sex in the conditional
zinb <- glmmTMB(tlf ~ jday_c + generation +length +year , zi = ~ jday_c + generation  +year , data = F12_mmdata, family = nbinom2)
summary(zinb)

# now julian day in the conditional
zinb <- glmmTMB(tlf ~  generation +length +year , zi = ~ jday_c + generation  +year , data = F12_mmdata, family = nbinom2)
summary(zinb)

# this looks pretty good
```

Final ZINB model by backward stepwise selection using Wald Tests is pretty interesting. The conditional part of the model includes an effect of generation, length, and year, while the additional zeros include generation day and year. At face value this suggests that release day affects fitness through the likelihood of reproducing at all, whereas length only matters if you do manage to spawn. This is the basic expectation for how this should work if we assume the zero part of the model largely predicts propensity for pre-spawn mortality whereas the conditional part predicts TLF once you do spawn. 

Now let's compare the the ZINB and NegBin models.

First we'll look at model validation

```{r}
simulateResiduals(negbin, plot = TRUE)
simulateResiduals(zinb, plot = TRUE)
```

Both model fits look good using simulated residuals.

Now let's compare using AIC, BIC and likelihood ratio tests (the negbin model is nested in the zinb model)

```{r}
anova(negbin, zinb)
```

ZINB best by AIC (delta AIC ~ 20) and likelihood ratio test, but worse by BIC. 

So the more complex ZINB model probably provides a better fit to the data. But what do we get for all this added model complexity? Let's examine the differences in the model fit on the response scale (TLF) using a hanging rootogram.

```{r}
# refit the final models with a different software to look at rootograms
negbin <- glm.nb(tlf ~  generation +length+ jday_c+year, data = F12_mmdata)

#rescale jday since this software has convergance issues
F12_mmdata %<>% mutate(jday_cs = scale(jday_c))
zinb <- zeroinfl(tlf ~  generation +length +year | jday_cs + generation +year , data = F12_mmdata, dist = "negbin")

rootogram(negbin, main = "Negative Binomial")
rootogram(zinb, main = "Zero-Inflated Negative Binomial")
```

These are nearly equivalent fits at all TLFs except 1. The negbin model is able to predict approximately the same number of zeros the ZINB model, without wildly differing at non-zeros. To me this suggests there isn't a severe zero-inflation problem and the same processes might drive fitness at both zeros and non-zeros.

Let's think about it this way, if both models offer similar explanatory power the benefit of the more complex model is additional inference between zero generating and non-zero generation processes (i.e. jday influences PSM whereas length influences TLF once you successfully survive to spawning time). Are we so confident in our model selection procedure that we should stake an entire conclusion on it? How much better is a model with exactly the same variables on both sides of the conditional/zero portions with respect to information/likelihood(AIC, LRT)

```{r}

zinb <- glmmTMB(tlf ~  generation +length +year , zi = ~ jday_c + generation  +year , data = F12_mmdata, family = nbinom2)

# here fit a model where the zero and conditional effects are the same and compare 
zinb2 <- glmmTMB(tlf ~ jday_c+ generation +length +year, zi = ~ jday_c + generation +length +year  , data = F12_mmdata, family = nbinom2)

# and compare
AIC(zinb, zinb2)
anova(zinb, zinb2)
```

Delta AIC is ~4, fails to be different in likelihood ratio test. This suggests the more complex model isn't worth it. Any decent results section would beed to consider both models above (with and without differences between zero and conditional sections).  
Instead we should defer to the negbin model. There is nothing wrong with model fit, it is nearly as good of a fit as the zinb, and it is much easier to get our central message across without having to explain the added complexity of model selection in a hurdle/zero-inflation model.

### Collinearity

Great, we know we want to use a negative binomial, and we know which variables might be collinear. Let's see if there is enough information to parse the effects of year, generation and sex on TLF. If we find strong collinearity then our power will be low, our estimates will have large SEs and the inferences we can draw will be limited.

We will do this using the VIF (or more specifically GVIF^(1/2*df)).

```{r}
# fit beyond optimal model (all possible fixed effect)
beyond_opt <- glm.nb(tlf ~ generation + length + sex+ jday_c+ year , data = F12_mmdata)
vif(beyond_opt)
```

Very low GVIFs! This is a relief considering the relationship between release day/generation, length/generation and year/generation. Despite these relationships, there is limited correlation between the estimates of their effects and we are likely to have sufficient power/information to identify their independent relationships with TLF.

We are clear to move on to model selection.

## Model Selection and Validation

Let's conduct model selection.

First we will examine the random effect structure, using REML. There is only a single random effect (release group). So, here we compare a mixed model with release group to it's equivalent glm with no random effects.
```{r}
beyond_opt_mm <- glmmTMB(tlf ~ generation + length + sex+ jday_c+ year + (1| group ) , data = F12_mmdata, family = nbinom2, REML = TRUE) 
beyond_opt <- glmmTMB(tlf ~ generation + length + sex+ jday_c+ year  , data = F12_mmdata, family = nbinom2, REML = TRUE)

AIC(beyond_opt_mm, beyond_opt)
BIC(beyond_opt_mm, beyond_opt)

```

Mixed model is a better performer. We will now switch to model selection for the fixed effect structure and fit using ML. The method is backward stepwise selection using likelihood ratio tests, and a cutoff of p = 0.05.

```{r}
beyond_opt_mm <- glmmTMB(tlf ~ generation*sex + length+ sex* jday_c+ year + (1| group ) , data = F12_mmdata, family = nbinom2) 
drop1(beyond_opt_mm, test = "Chisq") 

#drop sex*release day interaction

beyond_opt_mm <- glmmTMB(tlf ~ generation*sex + length + sex+ jday_c+ year + (1| group ) , data = F12_mmdata, family = nbinom2) 
drop1(beyond_opt_mm, test = "Chisq") 

#drop generation*sex interaction

beyond_opt_mm <- glmmTMB(tlf ~ generation + length + sex+ jday_c+ year + (1| group ) , data = F12_mmdata, family = nbinom2) 
drop1(beyond_opt_mm, test = "Chisq") 

#drop sex (p value = 0.63)
mm_f12 <- glmmTMB(tlf ~ generation + length +  jday_c+ year + (1| group ) , data = F12_mmdata, family = nbinom2) 
drop1(mm_f12, test = "Chisq") 

# Day of release only marginally improves model fit (delta AIC = 1.8, LRT p value = 0.053). Let's drop it.
mm_f12 <- glmmTMB(tlf ~ generation + length +   year + (1| group ) , data = F12_mmdata, family = nbinom2) 
drop1(mm_f12, test = "Chisq") 
```


We dropped (in order) sex * jday, sex * generation, sex, and day of release.
Now let's check the fit using simulated residuals.


```{r}
simulateResiduals(mm_f12, plot = TRUE)
```

Model fit is excellent.

## Final Model

```{r}
summary(mm_f12)
```

Generation (F0, F1, F2 and NORimmigrant), year (fixed effect factor four years) and length significantly improve the fit to the data according to LRT, AIC and Wald tests.

Let's look at the predicted effects

```{r, message = FALSE, warning = FALSE}

eff1 <- predictorEffect("generation", mm_f12)
effdf <- as.data.frame(eff1)
effdf$generation <- factor(effdf$generation, levels=c("HOR", "F1", "NORimmigrant")) # relevel the genertions for a nicer plot

#note that this throws an error. w/r/t this error the glmmTMB author (Ben Bolker) states that "the predicted variances are used when computing residuals (which are Pearson residuals by default) for partial residuals plots. I think that if you're not plotting partial residuals, it doesn't matter." 
# Since we do not plot partial residuals but instead th95 CI for the predition, we are good here

ggplot(data = effdf, aes(x = (generation), y = fit))+ 
  geom_point(position=position_dodge(width=0.3), size = 3) + 
  geom_errorbar(aes(ymin = lower, ymax = upper), position=position_dodge(width=0.3), width = 0.1)+ylab("TLF")+xlab("Generation")+theme_bw()
```

Let's do some post hoc testing analysis using marginal means in the emmeans packge.

We should think a lot and be very clear about how to weight observations across different levels of the other predictors here given the lack of balance in the data. For example, "classic" estimated marginal means where each level of year are given equal weights do not seem appropriate. We do not have an experiment so much as an observational dataset: variation in sample sizes between years and generation are not reflective of some kind of sampling process, but the biological reality in the river. Therefore we should not give equal weighting to the marginal mean for NOR fitness in 2015 where sample size is just 7% of what it is in 2012. We will use the "cell" based weighting scheme of the emmeans "reference grid," but we should also see how sensitive our results are to this decision and also use the default where everything is weighted equally (e.g. estimated marginal means)

```{r}
# we'll use emmeans for this
em <- emmeans(mm_f12, "generation", weights = "cell")
contrast(em, "pairwise", adjust = "Tukey", type = "response")
```

The novel finding here is that both NORimmigrants and F1s have greater fitness than HORs, but do not differ from one another.

# TLF Variation Kalinowski CIs

Our primary hypotheis testing method is to fit generalized linear mixed model that includes the factor "generation" as a fixed effect and then determine if the estimated effect of the different levels of this factor are significantly different from one another, once all other effects have been controlled for. This is likely the best way to address our questions given that the covariates length and year have such large effects on fitness, but let's not forget the clever approach that has been employed in past studies of RRS. 

The delta method takes advantage of the fact while TLF is a count variable with variance greater than the mean and requiring very advanced statistics to appropriately model, RRS is a ratio. If we are able to describe mean and variance of TLF for each of the groups we should be able to divide them by one another and generate a ratio, and a confidence interval for this ratio can be estimated using the a bit of clever math and likelihoods. If the confidence interval doesn't include one, then the fitness of the groups is different!

Let's use this approach for each year.

## Overall RRS

```{r, cache = TRUE, message=FALSE, warning=FALSE}
# kalinowski method
# rather than re-invent the wheel here let's make sure my interpretation of the Kalinowski paper is correct and modify seom existing code from a reviewed paper. My understanding matched the modified code here, so I just used that. We should be sure to cite if it winds up in a paper.
# https://doi.org/10.1098/rsos.221271

rrs_ci_kalinowski_auke <- function(n_h_off, n_w_off, n_h_par, n_w_par, alpha){
  chi_alpha <- qchisq(p = (1 - alpha), df = 1)
  n_off <- sum(c(n_h_off, n_w_off))
  n_par <- sum(c(n_h_par, n_w_par))
  
  rs_h <- n_h_off / n_h_par
  rs_w <- n_w_off / n_w_par
  
  p_h_par <- n_h_par / n_par
  p_w_par <- n_w_par / n_par
  
  rrs_h <- rs_h / rs_w
  rrs_w <- rs_w / rs_w
  rrs_avg <- (rrs_h * p_h_par) + (rrs_w * p_w_par)
  
  rrs_ml <- (n_h_off * log(p_h_par * rrs_h / rrs_avg)) + (n_w_off * log(p_w_par * rrs_w / rrs_avg))
  
  xi_dist <- bind_rows(
    lapply(seq(0.01, 50, by = 0.01), function(rrs_h_xi) { #upper RRS up to 50
      rrs_avg_xi <- (rrs_h_xi * p_h_par) + (rrs_w * p_w_par)
      tibble(rrs_crit = rrs_h_xi,
             logl = (n_h_off * log(p_h_par * rrs_h_xi / rrs_avg_xi)) + (n_w_off * log(p_w_par * rrs_w / rrs_avg_xi)) - (rrs_ml - chi_alpha / 2)
      )
    } )
  )
  
  rrs_min <- xi_dist %>% 
    mutate(abs_logl = abs(logl)) %>% 
    filter(rrs_crit < rrs_h) %>% 
    top_n(-1, abs_logl) %>% 
    pull(rrs_crit)
  
  rrs_max <- xi_dist %>% 
    mutate(abs_logl = abs(logl)) %>% 
    filter(rrs_crit > rrs_h) %>% 
    top_n(-1, abs_logl) %>% 
    pull(rrs_crit)
  
  return(c(rrs_min, rrs_h, rrs_max))
}

# get data to enter
rrs_delta <- F12_mmdata %>%
  group_by(generation, year) %>%
  summarise(n = n(), n_offspring = sum(tlf)) %>%
  pivot_wider(names_from = generation, values_from = c(n, n_offspring))


#n_h_off, n_w_off, n_h_par, n_w_par, alpha



# embarrisingly redundant, slow code, consider revising, can be made at least 3x faster by not calling the same function 3 times witht e same parameters...
# argument order reminder of function, n_h_off, n_w_off, n_h_par, n_w_par, alpha
rrs_delta %<>%
  rowwise() %>%
  mutate(rrs_NH_lwr = rrs_ci_kalinowski_auke(n_offspring_HOR, n_offspring_NORimmigrant, n_HOR, n_NORimmigrant, alpha = 0.05)[1],
         rrs_NH = rrs_ci_kalinowski_auke(n_offspring_HOR, n_offspring_NORimmigrant, n_HOR, n_NORimmigrant, alpha = 0.05)[2],
         rrs_NH_upr = rrs_ci_kalinowski_auke(n_offspring_HOR, n_offspring_NORimmigrant, n_HOR, n_NORimmigrant, alpha = 0.05)[3]) %>%
  mutate(rrs_FH_lwr = rrs_ci_kalinowski_auke(n_offspring_HOR, n_offspring_F1, n_HOR, n_F1, alpha = 0.05)[1],
         rrs_FH = rrs_ci_kalinowski_auke(n_offspring_HOR, n_offspring_F1, n_HOR, n_F1, alpha = 0.05)[2],
         rrs_FH_upr = rrs_ci_kalinowski_auke(n_offspring_HOR, n_offspring_F1, n_HOR, n_F1, alpha = 0.05)[3]) %>%
  mutate(rrs_FN_lwr = rrs_ci_kalinowski_auke(n_offspring_F1, n_offspring_NORimmigrant, n_F1, n_NORimmigrant, alpha = 0.05)[1],
         rrs_FN = rrs_ci_kalinowski_auke(n_offspring_F1, n_offspring_NORimmigrant, n_F1, n_NORimmigrant, alpha = 0.05)[2],
         rrs_FN_upr = rrs_ci_kalinowski_auke(n_offspring_F1, n_offspring_NORimmigrant, n_F1, n_NORimmigrant, alpha = 0.05)[3])
```

Now let's plot these.

```{r, message=FALSE, warning=FALSE}

plot_data <- rrs_delta %>%
  select(year, starts_with("rrs")) %>%
  pivot_longer(cols = -c(year), names_prefix = "rrs_", names_to = c("numerator", "value_type"), names_sep = "_", values_to = "value") %>%
  mutate(value_type = case_when(is.na(value_type) ~ "MeanRRS",
                                TRUE ~ value_type)) %>%
  pivot_wider(names_from = "value_type", values_from = "value") %>%
  mutate(numerator = as.factor(numerator),
         numerator = fct_relevel(numerator, "FN", "FH", "NH")) 

ggplot(plot_data)+geom_errorbar(aes(x = year, y = MeanRRS, ymin = lwr, ymax = upr, color = numerator), width = 0.3, position = position_dodge())+ geom_hline(aes(yintercept = 1), linetype = 2, color = "darkgrey")+theme_bw()+geom_point(aes(x = year, y = MeanRRS, color = numerator), size = 3,  position = position_dodge(width = 0.3))+xlab("")+scale_color_manual(name = "Contrast", values = c("#66CCEE", "#CCBB44", "#AA3377"), labels = c(expression(F[1]*" / NOR"),expression("HOR / " *F[1]), "HOR / NOR" ))+ylab(expression(" "[Delta]*"RRS"))+ theme(legend.text.align = 0) 

ggplot(plot_data)+geom_errorbar(aes(x = year, y = MeanRRS, ymin = lwr, ymax = upr, color = numerator), width = 0.3, position = position_dodge())+ geom_hline(aes(yintercept = 1), linetype = 2, color = "darkgrey")+theme_bw()+geom_point(aes(x = year, y = MeanRRS, color = numerator), size = 3,  position = position_dodge(width = 0.3))+xlab("")+scale_color_manual(name = "Contrast", values = c("#66CCEE", "#CCBB44", "#AA3377"), labels = c(expression(F[1]*" / NOR"),expression("HOR / " *F[1]), "HOR / NOR" ))+ylab(expression(" "[Delta]*"RRS"))+ theme(legend.text.align = 0) + coord_cartesian(ylim=c(0, 2))

#ggplot(plot_data)+geom_pointrange(aes(x = year, y = MeanRRS, ymin = lwr, ymax = upr, color = numerator), width = 0.3, position = position_dodge())+ geom_hline(aes(yintercept = 1), linetype = 2, color = "red")+theme_bw()
```

For the HOR RRSs, same results within each year (except 2015) using the delta method. RRS < 1 for regardless of whether F1s or NOR immigrants are in the numerator. Note that that this RRS calculation can't take differences in covariates like length and release day into effect.

Also note one important difference F1/NOR fitness is less than one in 2012.

```{r}
#Let's also calculate an overall RRS. Note that because some years have higher fitness than others, the unbalanced sample sizes across generation and year will create some major biases here and we shouldn't present this. 

rrs_delta_all <- F12_mmdata %>%
  group_by(generation) %>%
  summarise(n = n(), n_offspring = sum(tlf)) %>%
  pivot_wider(names_from = generation, values_from = c(n, n_offspring))

rrs_delta_all %<>%
  rowwise() %>%
  mutate(rrs_NH_lwr = rrs_ci_kalinowski_auke(n_offspring_HOR, n_offspring_NORimmigrant, n_HOR, n_NORimmigrant, alpha = 0.05)[1],
         rrs_NH = rrs_ci_kalinowski_auke(n_offspring_HOR, n_offspring_NORimmigrant, n_HOR, n_NORimmigrant, alpha = 0.05)[2],
         rrs_NH_upr = rrs_ci_kalinowski_auke(n_offspring_HOR, n_offspring_NORimmigrant, n_HOR, n_NORimmigrant, alpha = 0.05)[3]) %>%
  mutate(rrs_FH_lwr = rrs_ci_kalinowski_auke(n_offspring_HOR, n_offspring_F1, n_HOR, n_F1, alpha = 0.05)[1],
         rrs_FH = rrs_ci_kalinowski_auke(n_offspring_HOR, n_offspring_F1, n_HOR, n_F1, alpha = 0.05)[2],
         rrs_FH_upr = rrs_ci_kalinowski_auke(n_offspring_HOR, n_offspring_F1, n_HOR, n_F1, alpha = 0.05)[3]) %>%
  mutate(rrs_FN_lwr = rrs_ci_kalinowski_auke(n_offspring_F1, n_offspring_NORimmigrant, n_F1, n_NORimmigrant, alpha = 0.05)[1],
         rrs_FN = rrs_ci_kalinowski_auke(n_offspring_F1, n_offspring_NORimmigrant, n_F1, n_NORimmigrant, alpha = 0.05)[2],
         rrs_FN_upr = rrs_ci_kalinowski_auke(n_offspring_F1, n_offspring_NORimmigrant, n_F1, n_NORimmigrant, alpha = 0.05)[3])

```

## Sex Specific RRS

We also chose not to include sex specific RRS because sex and sex*generation interaction were not retained in the final model, but let's also split the delta method results up by sex and plot again to keep with conventions. 

__Males__
```{r, cache = TRUE}
# get data to enter
rrs_delta_males <- F12_mmdata %>%
  filter(sex == "M") %>%
  group_by(generation, year) %>%
  summarise(n = n(), n_offspring = sum(tlf)) %>%
  pivot_wider(names_from = generation, values_from = c(n, n_offspring))


#n_h_off, n_w_off, n_h_par, n_w_par, alpha



# embarrisingly redundant, slow code, consider revising, can be made at least 3x faster by not calling the same function 3 times witht e same parameters...
# argument order reminder of function, n_h_off, n_w_off, n_h_par, n_w_par, alpha
rrs_delta_males %<>%
  rowwise() %>%
  mutate(rrs_NH_lwr = rrs_ci_kalinowski_auke(n_offspring_HOR, n_offspring_NORimmigrant, n_HOR, n_NORimmigrant, alpha = 0.05)[1],
         rrs_NH = rrs_ci_kalinowski_auke(n_offspring_HOR, n_offspring_NORimmigrant, n_HOR, n_NORimmigrant, alpha = 0.05)[2],
         rrs_NH_upr = rrs_ci_kalinowski_auke(n_offspring_HOR, n_offspring_NORimmigrant, n_HOR, n_NORimmigrant, alpha = 0.05)[3]) %>%
  mutate(rrs_FH_lwr = rrs_ci_kalinowski_auke(n_offspring_HOR, n_offspring_F1, n_HOR, n_F1, alpha = 0.05)[1],
         rrs_FH = rrs_ci_kalinowski_auke(n_offspring_HOR, n_offspring_F1, n_HOR, n_F1, alpha = 0.05)[2],
         rrs_FH_upr = rrs_ci_kalinowski_auke(n_offspring_HOR, n_offspring_F1, n_HOR, n_F1, alpha = 0.05)[3]) %>%
  mutate(rrs_FN_lwr = rrs_ci_kalinowski_auke(n_offspring_F1, n_offspring_NORimmigrant, n_F1, n_NORimmigrant, alpha = 0.05)[1],
         rrs_FN = rrs_ci_kalinowski_auke(n_offspring_F1, n_offspring_NORimmigrant, n_F1, n_NORimmigrant, alpha = 0.05)[2],
         rrs_FN_upr = rrs_ci_kalinowski_auke(n_offspring_F1, n_offspring_NORimmigrant, n_F1, n_NORimmigrant, alpha = 0.05)[3])
```

```{r, message=FALSE, warning=FALSE}

plot_data <- rrs_delta_males %>%
  select(year, starts_with("rrs")) %>%
  pivot_longer(cols = -c(year), names_prefix = "rrs_", names_to = c("numerator", "value_type"), names_sep = "_", values_to = "value") %>%
  mutate(value_type = case_when(is.na(value_type) ~ "MeanRRS",
                                TRUE ~ value_type)) %>%
  pivot_wider(names_from = "value_type", values_from = "value") %>%
  mutate(numerator = as.factor(numerator),
         numerator = fct_relevel(numerator, "FN", "FH", "NH")) 
  
ggplot(plot_data)+geom_errorbar(aes(x = year, y = MeanRRS, ymin = lwr, ymax = upr, color = numerator), width = 0.3, position = position_dodge())+ geom_hline(aes(yintercept = 1), linetype = 2, color = "darkgrey")+theme_bw()+geom_point(aes(x = year, y = MeanRRS, color = numerator), size = 3,  position = position_dodge(width = 0.3))+xlab("")+scale_color_manual(name = "Contrast", values = c("#66CCEE", "#CCBB44", "#AA3377"), labels = c(expression(F[1]*" / NOR"),expression("HOR / " *F[1]), "HOR / NOR" ))+ylab(expression(" "[Delta]*"RRS"))+ theme(legend.text.align = 0) +ggtitle("RRS Males")

#ggplot(plot_data)+geom_pointrange(aes(x = year, y = MeanRRS, ymin = lwr, ymax = upr, color = numerator), width = 0.3, position = position_dodge())+ geom_hline(aes(yintercept = 1), linetype = 2, col

#kinda difficult to see 2012 CI let's zoom in 
ggplot(plot_data)+geom_errorbar(aes(x = year, y = MeanRRS, ymin = lwr, ymax = upr, color = numerator), width = 0.3, position = position_dodge())+ geom_hline(aes(yintercept = 1), linetype = 2, color = "darkgrey")+theme_bw()+geom_point(aes(x = year, y = MeanRRS, color = numerator), size = 3,  position = position_dodge(width = 0.3))+xlab("")+scale_color_manual(name = "Contrast", values = c("#66CCEE", "#CCBB44", "#AA3377"), labels = c(expression(F[1]*" / NOR"),expression("HOR / " *F[1]), "HOR / NOR" ))+ylab(expression(" "[Delta]*"RRS"))+ theme(legend.text.align = 0) +ggtitle("RRS Males")+coord_cartesian(ylim=c(0,4))
```

__Females__
```{r, cache = TRUE}
# get data to enter
rrs_delta_females <- F12_mmdata %>%
  filter(sex == "F") %>%
  group_by(generation, year) %>%
  summarise(n = n(), n_offspring = sum(tlf)) %>%
  pivot_wider(names_from = generation, values_from = c(n, n_offspring))


#n_h_off, n_w_off, n_h_par, n_w_par, alpha



# embarrisingly redundant, slow code, consider revising, can be made at least 3x faster by not calling the same function 3 times witht e same parameters...
# argument order reminder of function, n_h_off, n_w_off, n_h_par, n_w_par, alpha
rrs_delta_females %<>%
  rowwise() %>%
  mutate(rrs_NH_lwr = rrs_ci_kalinowski_auke(n_offspring_HOR, n_offspring_NORimmigrant, n_HOR, n_NORimmigrant, alpha = 0.05)[1],
         rrs_NH = rrs_ci_kalinowski_auke(n_offspring_HOR, n_offspring_NORimmigrant, n_HOR, n_NORimmigrant, alpha = 0.05)[2],
         rrs_NH_upr = rrs_ci_kalinowski_auke(n_offspring_HOR, n_offspring_NORimmigrant, n_HOR, n_NORimmigrant, alpha = 0.05)[3]) %>%
  mutate(rrs_FH_lwr = rrs_ci_kalinowski_auke(n_offspring_HOR, n_offspring_F1, n_HOR, n_F1, alpha = 0.05)[1],
         rrs_FH = rrs_ci_kalinowski_auke(n_offspring_HOR, n_offspring_F1, n_HOR, n_F1, alpha = 0.05)[2],
         rrs_FH_upr = rrs_ci_kalinowski_auke(n_offspring_HOR, n_offspring_F1, n_HOR, n_F1, alpha = 0.05)[3]) %>%
  mutate(rrs_FN_lwr = rrs_ci_kalinowski_auke(n_offspring_F1, n_offspring_NORimmigrant, n_F1, n_NORimmigrant, alpha = 0.05)[1],
         rrs_FN = rrs_ci_kalinowski_auke(n_offspring_F1, n_offspring_NORimmigrant, n_F1, n_NORimmigrant, alpha = 0.05)[2],
         rrs_FN_upr = rrs_ci_kalinowski_auke(n_offspring_F1, n_offspring_NORimmigrant, n_F1, n_NORimmigrant, alpha = 0.05)[3])
```

```{r, message=FALSE, warning=FALSE}

plot_data <- rrs_delta_females %>%
  select(year, starts_with("rrs")) %>%
  pivot_longer(cols = -c(year), names_prefix = "rrs_", names_to = c("numerator", "value_type"), names_sep = "_", values_to = "value") %>%
  mutate(value_type = case_when(is.na(value_type) ~ "MeanRRS",
                                TRUE ~ value_type)) %>%
  pivot_wider(names_from = "value_type", values_from = "value") %>%
  mutate(numerator = as.factor(numerator),
         numerator = fct_relevel(numerator, "FN", "FH", "NH")) 
  
ggplot(plot_data)+geom_errorbar(aes(x = year, y = MeanRRS, ymin = lwr, ymax = upr, color = numerator), width = 0.3, position = position_dodge())+ geom_hline(aes(yintercept = 1), linetype = 2, color = "darkgrey")+theme_bw()+geom_point(aes(x = year, y = MeanRRS, color = numerator), size = 3,  position = position_dodge(width = 0.3))+xlab("")+scale_color_manual(name = "Contrast", values = c("#66CCEE", "#CCBB44", "#AA3377"), labels = c(expression(F[1]*" / NOR"),expression("HOR / " *F[1]), "HOR / NOR" ))+ylab(expression(" "[Delta]*"RRS"))+ theme(legend.text.align = 0) +ggtitle("RRS Females")

#ggplot(plot_data)+geom_pointrange(aes(x = year, y = MeanRRS, ymin = lwr, ymax = upr, color = numerator), width = 0.3, position = position_dodge())+ geom_hline(aes(yintercept = 1), linetype = 2, col
```
Hard to see given the very high range in 2015. We'll make a second plot.

```{r}
ggplot(plot_data)+geom_errorbar(aes(x = year, y = MeanRRS, ymin = lwr, ymax = upr, color = numerator), width = 0.3, position = position_dodge())+ geom_hline(aes(yintercept = 1), linetype = 2, color = "darkgrey")+theme_bw()+geom_point(aes(x = year, y = MeanRRS, color = numerator), size = 3,  position = position_dodge(width = 0.3))+xlab("")+scale_color_manual(name = "Contrast", values = c("#66CCEE", "#CCBB44", "#AA3377"), labels = c(expression(F[1]*" / NOR"),expression("HOR / " *F[1]), "HOR / NOR" ))+ylab(expression(" "[Delta]*"RRS"))+ theme(legend.text.align = 0) +ggtitle("RRS Females")+ coord_cartesian(ylim=c(0,1.5))

```

### Results Summary

When split up by sex, HOR/NOR RRS < 1 for males in 2 of 4 years and for females in 3 of 4 years. 

HOR/F1 RRS < 1 for males in 2 of 4 years and for females in 3 of 4 years. 

F1/NOR RRS < 1 for males in 1 year and zero years for females.

# Differences among Offspring

We found that HORs, F1s and NOR immigrants produce different numbers of adult offspring, are there other differences in their offspring, such as age at maturity, or size ?

## AAM

The plot below can be a bit confusing so let's be clear. These plots show the age of OFFSPRING of each of the three groups, not the age of the groups.
```{r, message = FALSE, warning=FALSE}
pedigree_long <- pedigree %>%
  pivot_longer(-offspring_sample_id, names_to = "parent_sex", values_to = "parent")

off_age_F12 <- F12_mmdata %>%
  left_join(select(pedigree_long, -parent_sex), by = c("sample_id" = "parent")) %>%
  left_join(select(aam_data, offspring_sample_id, age)) %>%
  rename(offspring_age = age) %>%
  filter(!is.na(offspring_sample_id))

ggplot(off_age_F12)+geom_bar(aes(x = generation, fill = offspring_age))+scale_fill_viridis_d()+theme_bw()+xlab("parent")

#also make proportional
ggplot(off_age_F12)+geom_bar(aes(x = generation, fill = offspring_age), position = "fill")+scale_fill_viridis_d()+theme_bw()+xlab("parent")+ylab("proportion")

```

Yes, offspring of HOR parents tend to be younger than those F1s or NOR immigrants, but is this difference stronger than what we would expect by chance alone? Sample size in NOR immigrants is looking a little small.

Age at maturity is a count variable, but it could arguably be modeled as a continuous variable as well. Let's be sure to do it the "right" way here first. Given the way we defined age we need to recognize recognize that fish can either be 3, 4, 5 or 6 years old, and not 3.5 years old. 

### AAM GLM

First we should note that there are very few age-3 or age-6 offspring. If we remove these individuals, we can fit a binomial model. In other words we will parameterize a model that predicts the probability for the different groups to produce offspring that return at age 5 vs age 4. 

#### EDA and Modeling

Just like with the TLF we will be thoughtful about how to combine data across years. First let see if there is a relationship across years that we need to be concerned with.

```{r}
ggplot(off_age_F12)+geom_bar(aes(x = year, fill = offspring_age))+scale_fill_viridis_d()+theme_bw()+xlab("parent")+ylab("proportion")

```

Yes, 2015 is mostly age 4. We should be careful to look for multicollinearity and interactions.

First let's look at the relationship between year and generation and assess multicollinearity. We will assess with the GVIF.

```{r}
off_age_F12 %<>%
  filter(offspring_age %in% c("4", "5")) 

select(off_age_F12, generation, year, offspring_age) %>%
  pairs(., lower.panel = panel.cor, diag.panel = panel.hist, upper.panel = panel.smooth2)
  
gen_age_ind <- glm(offspring_age ~ generation + year , family = "binomial", data = off_age_F12)
# is there collinearity issue (e.g. does the impact of year and generation interact)
vif(gen_age_ind)

```

We know there's some balance issues among year already (most NOR immigrants come from 2012) and this shows up in the biplot. But it doesn't produce multicollinearity issues (GVIF is very small)

The next step is to see if there is an interaction

```{r}
gen_age_ind <- glm(offspring_age ~ generation * year , family = "binomial", data = off_age_F12)
drop1(gen_age_ind, test = "Chisq")
```

LRT suggests not ( p = 0.1, delta AIC ~ 1), so I think we are good to include year at the start of model selection as a fixed effect. 

```{r}
gen_age_ind <- glm(offspring_age ~ generation + year , family = "binomial", data = off_age_F12)
drop1(gen_age_ind, test = "Chisq")
# drop year, doesn't show up as significant, pvalue = 0.14 delta AIC < 1

gen_age_ind <- glm(offspring_age ~ generation , family = "binomial", data = off_age_F12)
drop1(gen_age_ind, test = "Chisq")
```

Final model is just generation. Let's validate, summarise the fit and do some post hoc tests.
```{r}
simulateResiduals(gen_age_ind , plot = TRUE)
summary(gen_age_ind)

em <- emmeans(gen_age_ind, "generation", type = "response", weights = "cell")
contrast(em, "pairwise", type = "response")
#ggplot(data = as.data.frame(em))+geom_pointrange(aes(x = generation, y = prob, ymin = asymp.LCL, ymax = asymp.UCL ))+theme_bw()+ylab("Proportion Age-5 Offspring\n vs. Age-4 Offspring")+xlab("Generation")



eff1 <- predictorEffect("generation", gen_age_ind)
effdf <- as.data.frame(eff1)
effdf$generation <- factor(effdf$generation, levels=c("HOR", "F1", "NORimmigrant")) # relevel the genertions for a nicer plot


ggplot(data = effdf, aes(x = (generation), y = fit))+ 
  geom_point(position=position_dodge(width=0.3), size = 3) + 
  geom_errorbar(aes(ymin = lower, ymax = upper), position=position_dodge(width=0.3), width = 0.1)+ylab("Proportion Age-5 Offspring\n vs. Age-4 Offspring")+xlab("Generation")+theme_bw()
```

We have a different pattern in this variable (aam of offspring), compared to TLF. F1s produce more age 5 offspring than HORs, but the confidence interval for the NOR immigrants overlaps __both__ F1s and HORs. 

## Size

What about size? Specifically do HORs F1s and NOR immigrants produce offspring that differ in size. Given our results so far we might expect either no difference, or that F1s and NORimmigrats produce larger offspring.

First let's take a look at the data. Can we fit a simple linear model here or do we need to incorporate covariates like we have elsewhere? Let's look at parent year by offspring size effects.
```{r,message=FALSE, warning=FALSE}
#let's put together the dataset
pedigree_long <- pedigree %>%
  pivot_longer(-offspring_sample_id, names_to = "parent_sex", values_to = "parent")

off_age_F12_2 <- F12_mmdata %>%
  left_join(select(pedigree_long, -parent_sex), by = c("sample_id" = "parent")) %>%
  left_join(select(aam_data, offspring_sample_id, age)) %>%
  rename(offspring_age = age) %>%
  filter(!is.na(offspring_sample_id))

off_age_F12_2 %<>%
  left_join(select(dedup, sample_id, length_off = length, year_off = year), by = c("offspring_sample_id" = "sample_id")) %>%
  mutate(year_off = as.factor(as.character(year_off)),
         year_f = as.factor(year))



ggplot(off_age_F12_2)+geom_histogram(aes(x = length_off, fill = year), bins = 20, position = position_dodge())+xlab("length of offspring (cm)")+ guides(fill=guide_legend(title="Parent Year"))+theme_bw()

ggplot(off_age_F12_2)+geom_histogram(aes(x = length_off, fill = year_off), bins = 20, position = position_dodge())+xlab("length of offspring (cm)")+ guides(fill=guide_legend(title="Offspring Year"))+theme_bw()


```

Yes, there are some very clear differences between parent years and offspring years in size. Which one to control for is an interesting question though. Let's choose to use parent year as the covariate. This has two benefits. First we are focusing on differences between the parents; age of their offspring is response variable. Second this will keep the paper easier to understand, since year will mean the same thing across models. 

We'll fit a linear model with two fixed effects, generation and (parent) year, check model assumptions and evaluate significance with an F-test and type II SS.

```{r}
#no this uses the wrong Sum of Squares
#summary(lm(length_off ~ generation + year_off, data = off_age_F12_2))

size_lm <- lm(length_off ~ generation + year_f , data = off_age_F12_2)

#plot(size_lm), no obvious issues here, let's move ahead

Anova(size_lm , type = "II")

```

No, significant effect of generation (p = 0.44) after controlling for year. Let's do some post hoc plotting (we shouldn't present this because the effect was not significant) .

```{r}
em <- emmeans(lm(length_off ~ generation + year_f, data = off_age_F12_2), "generation", type = "response")
#contrast(em, "pairwise", type = "response")
plot(em)


#ggplot(off_age_F12_2)+geom_histogram(aes(x = length_off, fill = generation), bins = 20, position = position_dodge())+xlab("length of offspring (cm)")+ guides(fill=guide_legend(title="Generation of Parent"))+scale_fill_manual(values = c("#4477AA", "#CCBB44", "#AA3377"))+theme_bw()
```

Results are similar in trend to age, but the confidence intervals are much wider, leading to no significant comparisons. 

# Miscellania

The sections above represent the final, concise analysis, but there are many little questions, cul de sacs, and supplemental analyses that are sometimes worth retaining for later. This section collects those. Not intended to be shared widely.

## Release Day Model

The effect of release day marginally improved the fit to the data, we should examine it alongside the final model. 

```{r}
mm_f12_wjday <- glmmTMB(tlf ~ generation + length +  jday_c+ year + (1| group ) , data = F12_mmdata, family = nbinom2) 
drop1(mm_f12_wjday, test = "Chisq") 

eff1 <- predictorEffect("generation", mm_f12_wjday)
effdf <- as.data.frame(eff1)
effdf$generation <- factor(effdf$generation, levels=c("HOR", "F1", "NORimmigrant")) # relevel the genertions for a nicer plot

#note that this throws an error. w/r/t this error the glmmTMB author (Ben Bolker) states that "the predicted variances are used when computing residuals (which are Pearson residuals by default) for partial residuals plots. I think that if you're not plotting partial residuals, it doesn't matter." 
# Since we do not plot partial residuals but instead th95 CI for the predition, we are good here

ggplot(data = effdf, aes(x = (generation), y = fit))+ 
  geom_point(position=position_dodge(width=0.3), size = 3) + 
  geom_errorbar(aes(ymin = lower, ymax = upper), position=position_dodge(width=0.3), width = 0.1)+ylab("TLF")+xlab("Generation")+theme_bw()

em <- emmeans(mm_f12_wjday, "generation", weights = "cell")
plot(em, alpha = 0.05, comparisons = TRUE, adjust = "none")
contrast(em, "pairwise", adjust = "Tukey", type = "response")
```

The results of the paper would be qualitatively the same had we chose this as our final model. RRS is less than one for both HOR/F1 and HOR/F1, but the RRS of F1/NOR = 1. Quantitatively there are some subtle differences that suggest that accounting for release day reduces the estimated fitness of F1s, but not enough to be significant or change any conclusions.

One thing we know from the big evaluation study is that the the effect of release day on fitness varies from year to year, but not enough to justify a random slopes model for year * release day. I don't think there is sufficient amount of data to build such a complex model, and it is unlikely to get better in future years given that downstream recycling post 2015 drastically reduces the number of NOR immigrants released above the dam.

## Carcass NOR Size

One concern with the NOR immigrants is that they are not representative of the broader McKenzie River wild population. Maybe they are late-season dispersers or strays with lower fitness? We can't directly address this because NORs are volitional migrators, not an experimentally trap-and-hauled "wild" salmon from throughout the basin. One way to compare using available data is size. We have size estimates from wild below dam spawners from spawning ground surveys conducted thoughout the study. Since we know size and fitness are closely related, this provides at least some information that might let us know if NORs are not representative of the broader wild McKenzie population.

```{r}
sgs_meta <- readxl::read_xlsx("../input_data/carcass_meta_data/McKenzie DNA missing_data_BoxUnableToSave_FinalDraft.xlsx", sheet = 1)

#now lets do some cleanup
sgs_meta %<>%
  mutate(length = case_when(`FL (cm)` > 111 ~ `FL (cm)`/10,
                            TRUE ~`FL (cm)` )) %>% #some lengths are in mm and some in cm, the largest cm is 111, we'll use this as a cutoff and convert 
  mutate(generation = "sgs_below_main") %>% # add a label
  mutate(year = lubridate::year(Date)) %>% #get years
  filter(year == 2012) %>% # filter years to match input data
#  filter(River == "South Fork McKenzie") %>%
  mutate(year = as.factor(year)) %>%
  mutate(sex = case_when(Sex == "M" ~ "M",
                         Sex == "Male" ~ "M",
                         Sex == "Female" ~ "F",
                         Sex == "F" ~ "F",
                         TRUE ~ NA_character_)) %>%
  drop_na(length) %>%
  drop_na(sex)

# now combine a with the dataset from the modeling

size_data <- F12_mmdata %>%
  select(generation, length, year, sex) %>%
  bind_rows(select(sgs_meta, generation, length, year, sex )) %>%
  filter(year == 2012)

size_data %>% count(generation, year) %>% pivot_wider(id_cols = year, names_from = generation, values_from = n)
```

There are 139 SF McKenzie NOR carcass samples from 2012 to 2015 that have a length measurement. There may be internannual variation in length, but the sample size * generation is pretty strongly unbalanced across years. Most carcass samples come from a year when few immigrants are sampled, 2015. Let's lump them all together and keep in mind that we can control for year only if we assume there is no year*generation interaction. We should maintain the possibility that NOR immigrants are different than wild spawners below the dam, regardless of the outcome of this analysis.

```{r}
ggplot(size_data)+geom_boxplot(aes(generation, length, color = year))+theme_bw()

ggplot(size_data)+geom_boxplot(aes(generation, length, color = sex))+theme_bw()

size_aov <- aov(length~ generation +  sex  , data = size_data)
Anova(size_aov, type = "II")
summary(size_aov)
#TukeyHSD(size_aov)  

#predictorEffect("generation", size_aov)

em <- emmeans(size_aov, "generation")
contrast(em, "pairwise", adjust = "Tukey", type = "response")
plot(em, comparisons = TRUE)
```

The only pairwise comparisons that are significant are those that include HORs (HORs always smaller) and F1s vs SGS. This suggests the NOR immigrants are not smaller (and less fit) than other NORs in the river, but the trend was there and significance was marginal. I don't think it's worth coming down one way or another here. 



## Final Figures

### Coastwide
In this section we plot key results from above for a powerpoint presentation. Eval flag is set to false for all of these so they should not produce anything.

```{r, eval = FALSE}
# First the TLF figure

eff1 <- predictorEffect("generation", mm_f12)
effdf <- as.data.frame(eff1)
effdf$generation <- factor(effdf$generation, levels=c("HOR", "F1", "NORimmigrant")) # relevel the genertions for a nicer plot

#note that this throws an error. w/r/t this error the glmmTMB author (Ben Bolker) states that "the predicted variances are used when computing residuals (which are Pearson residuals by default) for partial residuals plots. I think that if you're not plotting partial residuals, it doesn't matter." 
# Since we do not plot partial residuals but instead th95 CI for the predition, we are good here

ggplot(data = effdf, aes(x = (generation), y = fit))+ 
  geom_point(position=position_dodge(width=0.3), size = 3) + 
  geom_errorbar(aes(ymin = lower, ymax = upper), position=position_dodge(width=0.3), width = 0.1)+ylab("TLF")+xlab("Generation")+theme_bw()+theme(axis.text = element_text(size = 16, color = "black"))

ggplot(data = effdf)+geom_bar(aes(x = generation, y = fit, color = generation, fill = generation), stat = "identity")+geom_errorbar(aes(x = generation, ymin = lower, ymax = upper), position=position_dodge(width=0.3), width = 0.1)+ylab("TLF")+xlab("Generation")+theme_bw()+theme(axis.text.x = element_text(size = 18, color = "black"), axis.text.y = element_text(size = 14, color = "black"), axis.title = element_text(size = 18))+scale_x_discrete(labels = c( "HOR", expression(F[1]), "NOR"))+scale_fill_manual(values = c("#228833", "#CCBB44", "#AA3377"))+scale_color_manual(values = c("#228833", "#CCBB44", "#AA3377"))+guides(color = FALSE, fill =FALSE)
```


Yet another way to plot this would be as an RRS.

```{r, eval = FALSE}
em <- emmeans(mm_f12, "generation", weights = "cell")
rrs_model <- contrast(em, "pairwise", adjust = "Tukey", type = "response")
rrs_model <- as.data.frame(rrs_model) 
 
ggplot(data = rrs_model, aes(x = contrast, y = ratio))+ 
  geom_point(position=position_dodge(width=0.3), size = 3) + 
  geom_errorbar(aes(ymin = ratio - SE, ymax = ratio + SE), position=position_dodge(width=0.3), width = 0.1)+ylab(expression(" "[model]*"RRS"))+xlab("Contrast") + 
  theme_bw()+theme(axis.text.x = element_text(size = 16, color = "black"), axis.title = element_text(size = 16), axis.text.y = element_text(size = 12, color = "black")) + 
  scale_x_discrete(labels = c(expression(F[1]*" / NOR"),expression("HOR / " *F[1]), "HOR / NOR")) + 
  geom_hline(aes(yintercept = 1), linetype = 2, color = "darkgrey")+ ylim(0, 1.2)

```


```{r, eval = FALSE}
pedigree_long <- pedigree %>%
  pivot_longer(-offspring_sample_id, names_to = "parent_sex", values_to = "parent")

off_age_F12 <- F12_mmdata %>%
  left_join(select(pedigree_long, -parent_sex), by = c("sample_id" = "parent")) %>%
  left_join(select(aam_data, offspring_sample_id, age)) %>%
  rename(offspring_age = age) %>%
  filter(!is.na(offspring_sample_id))

ggplot(off_age_F12)+geom_bar(aes(x = generation, fill = offspring_age))+scale_fill_viridis_d(name = "Offspring\nAge")+theme_bw()+xlab("Parent Generation")+scale_x_discrete(labels = c( "HOR", expression(F[1]), "NOR"))+ylab("Count")+theme(axis.text.x = element_text(size = 18, color = "black"), axis.text.y = element_text(size = 14, color = "black"), axis.title = element_text(size = 18), legend.text = element_text(size = 14), , legend.title = element_text(size = 14))

#also make proportional
ggplot(off_age_F12)+geom_bar(aes(x = generation, fill = offspring_age), position = "fill")+scale_fill_viridis_d()+theme_bw()+xlab("parent")+ylab("proportion")

```

```{r, eval = FALSE}

em <- emmeans(gen_age_ind, "generation", type = "response")
contrast(em, "pairwise", type = "response")
#ggplot(data = as.data.frame(em))+geom_pointrange(aes(x = generation, y = prob, ymin = asymp.LCL, ymax = asymp.UCL ))+theme_bw()+ylab("Proportion Age-5 Offspring\n vs. Age-4 Offspring")+xlab("Generation")



eff1 <- predictorEffect("generation", gen_age_ind)
effdf <- as.data.frame(eff1)
effdf$generation <- factor(effdf$generation, levels=c("HOR", "F1", "NORimmigrant")) # relevel the genertions for a nicer plot


ggplot(data = effdf, aes(x = (generation), y = fit))+ 
  geom_point(position=position_dodge(width=0.3), size = 3) + 
  geom_errorbar(aes(ymin = lower, ymax = upper), position=position_dodge(width=0.3), width = 0.1)+ylab("Proportion Age-5 Offspring\n vs. Age-4 Offspring")+xlab("Generation")+theme_bw()


ggplot(data = effdf)+geom_bar(aes(x = generation, y = fit, color = generation, fill = generation), stat = "identity") + 
  geom_errorbar(aes(x = generation, ymin = lower, ymax = upper), position=position_dodge(width=0.3), width = 0.1) +
  ylab("Proportion Age-5 Offspring\n vs. Age-4 Offspring") + xlab("Generation") + 
  theme_bw() + 
  theme(axis.text.x = element_text(size = 18, color = "black"), axis.text.y = element_text(size = 14, color = "black"), axis.title = element_text(size = 18)) + 
  scale_x_discrete(labels = c( "HOR", expression(F[1]), "NOR")) + 
  scale_fill_manual(values = c("#228833", "#CCBB44", "#AA3377")) + 
  scale_color_manual(values = c("#228833", "#CCBB44", "#AA3377")) + 
  guides(color = FALSE, fill =FALSE)
```

